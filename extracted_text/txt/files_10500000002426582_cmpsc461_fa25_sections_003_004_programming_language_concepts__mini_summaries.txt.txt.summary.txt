Lexical analysis, the compiler's first phase, transforms character streams into tokens (lexeme + attribute) by matching patterns, typically regular expressions. It removes non-significant characters, handles lookahead, and manages errors. Regular expressions formally define these patterns and regular languages using alphabets, strings, and operations like concatenation, union, and iteration, enabling powerful pattern matching.